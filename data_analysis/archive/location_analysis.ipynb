{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2445131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import requests\n",
    "import ast\n",
    "import deepl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d38f834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = deepl.Translator(\"6780cef2-4c9d-787f-4999-9649bd278538:fx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f9d3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp1 = spacy.load(\"de_core_news_sm\")  # Model 1\n",
    "nlp2 = spacy.load('de_core_news_md')  # Model 2\n",
    "nlp3 = spacy.load('de_core_news_lg')  # Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f45cc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_german = pd.read_csv('../scraping/data/extractor_all_articles_20minuten.csv')\n",
    "df_french = pd.read_csv('../scraping/data/extractor_all_articles_20minutes.csv')\n",
    "df_italian = pd.read_csv('../scraping/data/extractor_all_articles_20minuti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_countries = pd.read_csv('dicts/allCountries.csv')\n",
    "known_locations = set(dict_all_countries['LocationName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "588c6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_countries['BiggerEntity'] = dict_all_countries['CountryName'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c924afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_location_names = dict_all_countries['BiggerEntity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2939591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_german(text):\n",
    "    try:\n",
    "        result = translator.translate_text(text, target_lang=\"DE\")\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during translation: {e}\")\n",
    "        return None  # Return None if translation fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "630d0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during translation: text parameter must be a string or an iterable of strings\n"
     ]
    }
   ],
   "source": [
    "translated_names = {name: translate_to_german(name) for name in unique_location_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8894a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_translation_mapping = {original: translated_names[original] for original in unique_location_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95927858",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_countries['BiggerEntity_German'] = dict_all_countries['BiggerEntity'].map(name_translation_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8c70e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_locations = set(dict_all_countries['BiggerEntity_German'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa01a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_locations.update(new_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ea0ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations_with_voting_system(text, known_locations):\n",
    "    # Process the text with all three models\n",
    "    doc1 = nlp1(text)\n",
    "    doc2 = nlp2(text)\n",
    "    doc3 = nlp3(text)\n",
    "    \n",
    "    # Extract locations from each model\n",
    "    locations1 = {ent.text for ent in doc1.ents if ent.label_ == 'LOC'}\n",
    "    locations2 = {ent.text for ent in doc2.ents if ent.label_ == 'LOC'}\n",
    "    locations3 = {ent.text for ent in doc3.ents if ent.label_ == 'LOC'}\n",
    "    \n",
    "    # Perform a majority vote\n",
    "    all_locations = locations1 | locations2 | locations3\n",
    "    final_locations = {loc for loc in all_locations if sum([loc in locations for locations in [locations1, locations2, locations3]]) >= 2}\n",
    "    \n",
    "    # Filter final locations to include only those in the known locations\n",
    "    final_known_locations = {loc for loc in final_locations if loc in known_locations}\n",
    "    \n",
    "    return final_known_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a2f3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_similar_entities(entities):\n",
    "    merged_entities = set()\n",
    "    for entity in entities:\n",
    "        if not any(e for e in merged_entities if entity in e or e in entity):\n",
    "            merged_entities.add(entity)\n",
    "    return merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef49a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_location(loc):\n",
    "    articles = {'der', 'die', 'das', 'den'}\n",
    "    words = loc.split()\n",
    "    normalized_words = [word for word in words if word.lower() not in articles]\n",
    "    return ' '.join(normalized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6641fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations(text):\n",
    "    doc = nlp1(text)\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ == 'LOC']\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55f5ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations(text, known_locations):\n",
    "    doc = nlp1(text)\n",
    "    # Define locations based on SpaCy's entity recognition\n",
    "    extracted_locations = [ent.text for ent in doc.ents if ent.label_ == 'LOC']\n",
    "    # Filter the locations based on your known locations set\n",
    "    locations = [loc for loc in extracted_locations if loc in known_locations]\n",
    "    return locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a255a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations(text):\n",
    "    doc = nlp1(text)\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ == 'LOC']\n",
    "    return locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba0b1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_german['Voted_Locations_New'] = df_german['Content'].apply(lambda text: extract_locations_with_voting_system(text, known_locations))\n",
    "df_german['Locations_New'] = df_german['Content'].apply(lambda text: extract_locations(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c40a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_counts_new = df_german['Locations_New'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2c3b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location_counts = location_counts_new.reset_index()\n",
    "df_location_counts.columns = ['LocationName', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd197c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the location names\n",
    "df_location_counts['NormalizedLocation'] = df_location_counts['LocationName'].apply(normalize_location)\n",
    "\n",
    "# Group by the normalized names and sum the counts\n",
    "grouped_df_location_counts = df_location_counts.groupby('NormalizedLocation').agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "# Sort the DataFrame by the counts in descending order\n",
    "sorted_grouped_df_location_counts = grouped_df_location_counts.sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "035267b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_over_10_mentions = sorted_grouped_df_location_counts[sorted_grouped_df_location_counts['Count'] > 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "935b2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = locations_over_10_mentions['NormalizedLocation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bad6c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_remove = ['Tiktok', 'Bund', 'US-Präsident', 'Problem', 'Instagram', 'Bundesgericht', 'Ki', 'Bewohner', 'Züri Fäscht', 'Gesamt-Skigebiet', 'Hause', 'Bildstrecke']\n",
    "\n",
    "# Remove the unwanted terms from the locations list\n",
    "filtered_locations = [loc for loc in locations_list if loc not in terms_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5ddc81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_locations.update(filtered_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "361cc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations_with_voting_system(text, known_locations):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Process the lowercased text with all three models\n",
    "    doc1 = nlp1(text)\n",
    "    doc2 = nlp2(text)\n",
    "    doc3 = nlp3(text)\n",
    "    \n",
    "    # Extract locations from each model and convert them to lowercase\n",
    "    locations1 = {ent.text.lower() for ent in doc1.ents if ent.label_ == 'LOC'}\n",
    "    locations2 = {ent.text.lower() for ent in doc2.ents if ent.label_ == 'LOC'}\n",
    "    locations3 = {ent.text.lower() for ent in doc3.ents if ent.label_ == 'LOC'}\n",
    "    \n",
    "    # Perform a majority vote\n",
    "    all_locations = locations1 | locations2 | locations3\n",
    "    final_locations = {loc for loc in all_locations if sum([loc in locations for locations in [locations1, locations2, locations3]]) >= 2}\n",
    "    \n",
    "    # Ensure known_locations is also lowercase\n",
    "    lower_known_locations = {loc.lower() for loc in known_locations}\n",
    "    \n",
    "    # Filter final locations to include only those in the lowercase known locations\n",
    "    final_known_locations = {loc for loc in final_locations if loc in lower_known_locations}\n",
    "    \n",
    "    return final_known_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c439fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_known_locations = {location.lower() for location in known_locations if location is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3dee073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_german['Content'] = df_german['Content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c94cafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_german['Voted_Locations'] = df_german['Content'].apply(lambda text: extract_locations_with_voting_system(text, lower_known_locations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6eccfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_location_counts_new = df_german['Voted_Locations'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3230eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_to_remove = {'st.', 'bund'}\n",
    "\n",
    "# Remove these entries from the set\n",
    "voted_location_counts_new = {entry for entry in voted_location_counts_new if entry not in entries_to_remove}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55e6d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voted_locations = voted_location_counts_new.reset_index()\n",
    "df_voted_locations.columns = ['LocationName', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71886c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_to_remove = {'st.', 'tiktok', 'us-präsident','problem', 'bund', 'hause', 'land', 'erde', 'aa', 'instagram', 'bundesgericht', 'ki', 'bewohner', 'züri fäscht', 'gesamt-skigebiet', 'bildstrecke'}\n",
    "df_voted_locations = df_voted_locations[~df_voted_locations['LocationName'].isin(entries_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c7f82cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/occuring_locations_german.csv'\n",
    "df_voted_locations.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e947c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_location_positionstack(location_name, api_key):\n",
    "    base_url = \"http://api.positionstack.com/v1/forward\"\n",
    "    params = {\n",
    "        'access_key': api_key,\n",
    "        'query': location_name,\n",
    "        'limit': 1,  # you may adjust the limit as needed\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Check if data['data'] is not empty to avoid index errors\n",
    "        if data['data']:\n",
    "            latitude = data['data'][0]['latitude']\n",
    "            longitude = data['data'][0]['longitude']\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e131da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_voted_locations[df_voted_locations['Count'] >= 3].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2922d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_api_key = '1983e85e9a97673a09ed6d19417dda0f'\n",
    "\n",
    "df_filtered['Coordinates'] = df_filtered['LocationName'].apply(\n",
    "    lambda loc: geocode_location_positionstack(loc, geocode_api_key)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "078c382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['Coordinates'] = df_filtered['Coordinates'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a90dff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/df_filtered.csv'\n",
    "\n",
    "df_filtered.to_csv(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
